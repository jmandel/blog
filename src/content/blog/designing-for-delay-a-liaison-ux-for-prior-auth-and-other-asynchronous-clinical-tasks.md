---
title: "Designing for Delay: A Liaison UX for Prior Auth and Other Asynchronous Clinical Tasks"
date: 2025-01-01T00:00:00
slug: designing-for-delay-a-liaison-ux-for-prior-auth-and-other-asynchronous-clinical-tasks
banner: "https://media.licdn.com/mediaD5612AQGyR0dBUBhoVA"
---
<p>Clinical workflows are full of necessary steps that don't happen instantly. Think about <strong>prior authorization (PA)</strong> – a classic example – but also tasks like <strong>matching a patient to eligible clinical trials</strong>, or coordinating a complex specialty consult requiring information exchange. These processes are often asynchronous, involve multiple steps, require gathering information from various sources, and can take minutes, hours, or even days.</p><p>Recently I posted about the pain points in PA workflows, asking "<a href="https://www.linkedin.com/pulse/prior-auth-friction-cant-we-just-talk-josh-mandel-md-taq6c/" target="_blank">Prior auth is friction. Can't we just talk?</a>". The core idea was exploring how LLM agents, embedded in EHRs and communicating via standardized protocols, could handle the necessary dialogue, moving beyond today's rigid, often frustrating, structured data exchanges. This echoes challenges we faced years ago; when I first drafted the <a href="https://cds-hooks.org/" target="_blank"><strong>CDS Hooks specification</strong></a> back in 2015, we aimed to embed external logic seamlessly, but primarily focused on synchronous suggestions via static Cards. While useful, that pattern isn't inherently designed for the <em>persistent, multi-step, asynchronous dialogues</em> that characterize these more complex tasks.</p><p>Last week, I shared a demo showing the "<a href="https://www.linkedin.com/pulse/theory-practice-llm-agents-using-mcp-tools-real-ehr-data-mandel-md-acknc/" target="_blank">agent + tools" pattern in action</a>, leveraging the <strong>Model Context Protocol (MCP)</strong> to let an LLM securely use tools against real EHR data fetched via SMART on FHIR. This reinforced the idea that our focus should be on robust data access (FHIR) and interoperable tool protocols (MCP), letting capable agents handle the dynamic parts.</p><p>But how do we <em>manage</em> these agent interactions within the EHR user experience, especially when delays are inherent? We need a more dynamic approach.</p><p>This brings us to a UX paradigm I'm calling the <strong>Liaison Model</strong>. Imagine an internal LLM agent embedded within the EHR – the <strong>"Liaison"</strong>. Its primary role isn't to <em>be</em> the specialized external tool (like the payer's PA engine), but to <em>orchestrate the interaction</em> with it, acting as an intelligent intermediary between the EHR user, the EHR data, and the external agent.</p><p>When a workflow event triggers a need for an asynchronous task, the Liaison initiates a <strong>Task</strong> representation. It then identifies and communicates with the appropriate external agent(s), potentially using standardized protocols like an <strong>Agent-to-Agent (A2A)</strong> framework for managing the conversation. Crucially, the Liaison leverages its secure, internal access to EHR data (via <strong>FHIR</strong> APIs) and its own toolkit (perhaps including <strong>MCP</strong>-defined tools run locally/securely) to proactively gather context and attempt to fulfill the external agent's requests. It manages the task's lifecycle through various states (Submitted, Working, Needs Input, Completed, Failed). While the FHIR standard itself offers a robust Task resource that could model this state in detail, the focus here is on the user-facing experience.</p><p>Perhaps the most critical function of the Liaison is <strong>mediated user interaction</strong>. It handles the automated back-and-forth with external agents. Only when it encounters ambiguity, requires clinical judgment it cannot derive, or hits a necessary human checkpoint does it pause that thread and flag the Task as needing user input, presenting a specific, targeted request within the task's context. (At the same time, all of a Liaison's work is transparent, available for the user to review or audit at any time.)</p><p>This UX model matters because it embraces the <strong>reality of these complex clinical tasks</strong>. Many <em>could</em> theoretically be fully automated, but often require human intervention for validation or handling edge cases. Even fully automated agent interactions might involve multiple turns and delays. We need a user experience that acknowledges asynchronicity, provides visibility without constant interruption, manages complexity by hiding intricate details unless requested, and facilitates focused user input when necessary.</p><p>The underlying technology – protocols like A2A for structuring dialogue, MCP for defining tool use, and agent development toolkits like LangChain/LangGraph or AutoGen for implementation – provides the necessary plumbing. This discussion centers on the <strong>UX layer</strong> built on top of that foundation. It’s about <em>how</em> these agent interactions manifest for the clinician within their workflow.</p><p>Here’s how the Liaison UX might look in practice:</p><p>1.  <strong>Inline Initiation &amp; Subtle Status:</strong> When a task like a PA request begins, an <strong>inline status indicator</strong> appears next to the relevant order. It's initially unobtrusive – perhaps a small, grayed-out icon or highlight with brief text like "PA: Submitted". The user acknowledges the background process and continues working.</p><p>2.  <strong>Louder Signal for Action:</strong> If the Liaison needs human input, the indicator <strong>becomes visually "louder"</strong> – a more prominent icon (maybe a question mark) in a noticeable color (like amber), with text like "PA: Needs Input". It attracts attention to the specific item requiring action.</p><p>3.  <strong>Contextual Task Details Panel:</strong> Clicking the indicator opens a dedicated panel. This provides the <strong>current status</strong>, a transparent <strong>message history</strong> showing the Liaison-Agent interactions and the reason for needing input, any generated <strong>artifacts</strong> (like draft forms or results), and importantly, a <strong>focused input area</strong> that <em>only appears</em> when the status is "Needs Input", presenting the specific question from the Liaison.</p><p>4.  <strong>Seamless Handoff &amp; Quiet Resumption:</strong> The user provides the requested information in the panel. The Liaison processes it, sends it along, and the <strong>inline indicator reverts to its quieter "Working" state</strong>. The input area disappears, and the task continues in the background.</p><p>5.  <strong>Clear Completion Indicator:</strong> Once the task finishes, the inline indicator shows a clear final state – a success icon (checkmark) with "PA: Approved" or a failure icon with "PA: Denied".</p><p>6.  <strong>The Task Inbox: Integration and Overview:</strong> While inline indicators offer context, clinicians need a consolidated view. Liaison-managed tasks can be aggregated in a dedicated panel or, ideally, <strong>integrated directly into existing EHR task systems</strong>. This view lists tasks across patients, clearly highlighting those needing user input for prioritization. Herein lies a key advantage: instead of needing deep, bespoke EHR integrations for every external agent service, the EHR integrates <em>once</em> with the Liaison framework via standard protocols (A2A, MCP). The <strong>Liaison LLM acts as the adaptable bridge</strong>, translating the diverse requirements and dialogues of various external agents into a consistent task representation suitable for the EHR's task system. This significantly lowers the barrier for incorporating multiple useful agent-driven services.</p><p>This Liaison UX pattern aims to gracefully handle delays, orchestrate complexity behind the scenes, increase transparency, minimize user burden by focusing interactions, and maintain context while offering a consolidated overview. Crucially, it enables scalable integration of diverse asynchronous services through standardization.</p><p>As AI agents become more embedded in healthcare, effectively managing these asynchronous interactions is vital. The Liaison model, leveraging standard protocols and focusing on a human-centered UX that designs for delay, offers a path toward more seamless, efficient, and scalable integration of agentic capabilities into the reality of clinical work.</p><p>Follow-up post with live demo: <a href="https://www.linkedin.com/m/pulse/conversational-interop-prior-auth-demo-josh-mandel-md-wjwxe" target="_blank"><strong>https://www.linkedin.com/m/pulse/conversational-interop-prior-auth-demo-josh-mandel-md-wjwxe</strong></a></p>